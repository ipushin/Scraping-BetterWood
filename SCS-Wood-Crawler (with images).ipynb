{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pickle\n",
    "import requests\n",
    "import math\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import cfscrape\n",
    "from lxml import etree\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('/Users/macbook/Downloads/Chrome Driver/chromedriver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting products links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_collection = ['https://www.scs-holzshop.de/holzbalken/', \n",
    "                      'https://www.scs-holzshop.de/hobelware-latten/',\n",
    "                      'https://www.scs-holzshop.de/platten-daemmstoffe/',\n",
    "                      'https://www.scs-holzshop.de/terrasse/',\n",
    "                      'https://www.scs-holzshop.de/holzbalken/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_links = []\n",
    "for n in range(len(products_collection)):\n",
    "    \n",
    "    \n",
    "    # number of pages\n",
    "    url = products_collection[n] + '?limit=96'\n",
    "    browser.get(url)\n",
    "    \n",
    "    try:\n",
    "        sleep(5)\n",
    "        pages = browser.find_elements_by_xpath('//*[@class=\"pages\"]//li')[-2].text\n",
    "        pages = int(pages)\n",
    "    except:\n",
    "        pages=1\n",
    "        pass\n",
    "    \n",
    "    print('\\nSection:', n+1, '|', '#Pages:', pages,  '|', products_collection[n])\n",
    "    \n",
    "    section_links = []\n",
    "    for page in range(1, pages+1):\n",
    "        \n",
    "        url = products_collection[n] + '?limit=96' + '&p={}'.format(page)\n",
    "        browser.get(url)\n",
    "        sleep(3)\n",
    "        \n",
    "        elems = browser.find_elements_by_xpath('//*[@class=\"products-list__action\"]//a[@href]')\n",
    "        page_links = []\n",
    "        for elem in elems:\n",
    "            link = elem.get_attribute(\"href\")\n",
    "            page_links.append(link)\n",
    "        \n",
    "        print('#', page, 'Got links for page:', len(page_links))\n",
    "        section_links.extend(page_links)\n",
    "    \n",
    "    all_links.extend(section_links)\n",
    "    print('Got links for section:', len(section_links))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicating links\n",
    "product_links = []\n",
    "for i in all_links:\n",
    "    if i not in product_links:\n",
    "        product_links.append(i)\n",
    "len(product_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting url options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "option_one_links = []\n",
    "option_two_links = []\n",
    "other_option_links = []\n",
    "waiting_time = 15\n",
    "for i in range(len(product_links))\n",
    "    link = product_links[i]\n",
    "    browser.get(link)\n",
    "    sleep(2)\n",
    "    \n",
    "    # Dim One\n",
    "    try:\n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dd[1]'\n",
    "        first_input = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for f_i, f_j in enumerate(first_input, start=1):\n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dd[1]/div/div/div[{}]'.format(f_i)\n",
    "        try:\n",
    "            element = WebDriverWait(browser, waiting_time).until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "            element.click()\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Dim Two\n",
    "    try:\n",
    "        sleep(2)  \n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dd[2]'\n",
    "        second_input = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for s_i, s_j in enumerate(second_input, start=1):\n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dd[2]/div/div/div[{}]'.format(s_i)        \n",
    "        sleep(1)\n",
    "        \n",
    "        try:\n",
    "            element = WebDriverWait(browser, waiting_time).until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "            element.click()\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    try:\n",
    "       \n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dd[3]/div/div/div[1]'\n",
    "        element = WebDriverWait(browser, waiting_time).until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "        element.click()\n",
    "        sleep(2)\n",
    "        opt_three = browser.find_element_by_xpath(path).text\n",
    "        if opt_one and opt_two and opt_three:\n",
    "            print(i, 'Option One', link)\n",
    "            option_one_links.append(link)\n",
    "            continue\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Check Option Two\n",
    "    try:\n",
    "       \n",
    "        length_path = '//*[@id=\"product-options-wrapper\"]/div[2]/dl/dd/div/div/input'\n",
    "        browser.find_element_by_xpath(length_path).send_keys('-9999')\n",
    "        print(i, 'Option Two', link)\n",
    "        option_two_links.append(link)\n",
    "    \n",
    "    except:\n",
    "        print(i, 'OTHER Option', link)\n",
    "        other_option_links.append(link)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all links were mapped to options\n",
    "[x for x in product_links if x not in other_option_links and x not in option_two_links and x not in option_one_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(option_one_links), len(option_two_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('/Users/macbook/Downloads/Chrome Driver/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "waiting_time = 20\n",
    "start=1\n",
    "for idx, page_link in enumerate(option_one_links[:], start=start):\n",
    "    print('\\nPage:', idx, 'out of', len(option_one_links))\n",
    "    print('-'*80)\n",
    "    browser.get(page_link)\n",
    "    sleep(2)\n",
    "    full_product_df = pd.DataFrame()\n",
    "    \n",
    "    # First Option\n",
    "    path = '//*[@id=\"product-options-wrapper\"]/dl/dd[1]/div'\n",
    "    first_input = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "\n",
    "    path = '//*[@id=\"product-options-wrapper\"]/dl/dt[1]'\n",
    "    first_option_name = browser.find_element_by_xpath(path).text\n",
    "    opt_num = []\n",
    "    for f_i, first_opt in enumerate(first_input, start=1):\n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dd[1]/div/div/div[{}]'.format(f_i)\n",
    "\n",
    "        try:\n",
    "            element = WebDriverWait(browser, waiting_time).until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "            element.click()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Second Option\n",
    "        sleep(4)  \n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dd[2]/div'\n",
    "        second_input = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "\n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dt[2]'\n",
    "        second_option_name = browser.find_element_by_xpath(path).text\n",
    "        \n",
    "        \n",
    "\n",
    "        for s_i, second_opt in enumerate(second_input, start=1):\n",
    "\n",
    "            sleep(4) \n",
    "            try:\n",
    "                path = '//*[@id=\"product-options-wrapper\"]/dl/dd[2]/div/div/div[{}]'.format(s_i)  \n",
    "                element = WebDriverWait(browser, waiting_time).until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "                element.click()\n",
    "                sleep(2)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # Initiating page dataset\n",
    "            page_df = pd.DataFrame()\n",
    "\n",
    "            # Third Option\n",
    "            path = '//*[@id=\"product-options-wrapper\"]/dl/dd[3]/div'\n",
    "            third_input = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "\n",
    "            path = '//*[@id=\"product-options-wrapper\"]/dl/dt[3]'\n",
    "            third_option_name = browser.find_element_by_xpath(path).text\n",
    "            \n",
    "            \n",
    "            opt_num.append(len(third_input))\n",
    "            \n",
    "            for t_i, third_opt in enumerate(third_input, start=1): \n",
    "\n",
    "                # Specific product dataset\n",
    "                product_df = pd.DataFrame([], index=[0])\n",
    "                product_df[first_option_name + '-T'] = first_opt\n",
    "                product_df[second_option_name + '-T'] = second_opt\n",
    "                product_df[third_option_name + '-T'] = np.nan\n",
    "                product_df['Price'] = np.nan\n",
    "                product_df['Delivery'] = np.nan\n",
    "                product_df['Description'] = np.nan\n",
    "\n",
    "                \n",
    "                sleep(1)\n",
    "\n",
    "                try:\n",
    "                    path = '//*[@id=\"product-options-wrapper\"]/dl/dd[3]/div/div/div[{}]'.format(t_i)\n",
    "                    element = WebDriverWait(browser, waiting_time).until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "                    element.click()\n",
    "                    sleep(1)\n",
    "\n",
    "                    # Mapping Third Dimention\n",
    "                    product_df[third_option_name + '-T'] = third_opt\n",
    "\n",
    "                    # Price\n",
    "                    sleep(1)\n",
    "                    path = '//*[@class=\"price-box\"]'\n",
    "                    price = browser.find_element_by_xpath(path).text\n",
    "                    product_df['Price'] = price\n",
    "\n",
    "                    # Delivery\n",
    "                    path = '//*[@class=\"product-view__delivery-time\"]'\n",
    "                    delivery = browser.find_element_by_xpath(path).text\n",
    "                    product_df['Delivery'] = delivery\n",
    "\n",
    "                    # Description\n",
    "                    path = '//*[@class=\"product-view__collateral-main\"]'\n",
    "                    description = browser.find_element_by_xpath(path).text\n",
    "                    product_df['Description'] = description\n",
    "\n",
    "                    # Specification\n",
    "                    html = browser.page_source\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    tech_data = {}\n",
    "                    labels = soup.findAll(\"dt\", { \"class\" : \"technical-data__label\" })\n",
    "                    values = soup.findAll(\"dd\", { \"class\" : \"technical-data__value\" })\n",
    "                    for i in range(len(labels)):\n",
    "                        tech_data[labels[i].text] = values[i].text\n",
    "                    tech_data = pd.DataFrame([tech_data], index=[0])\n",
    "\n",
    "                    product_df = pd.concat([product_df, tech_data], axis=1)\n",
    "                    page_df = pd.concat([page_df, product_df], ignore_index=True)\n",
    "                    page_df['URL'] = page_link\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "            try:  \n",
    "                print(('Page Table Size:'), page_df.dropna(subset= [third_option_name + '-T']).shape[0], 'Expected Size', len(third_input))\n",
    "            except:\n",
    "                print(('Page Table Size:'), page_df.dropna().shape[0], 'Expected Size', len(third_input))\n",
    "                pass\n",
    "            \n",
    "            full_product_df = pd.concat([full_product_df, page_df], ignore_index=True)\n",
    "            \n",
    "    est_qnt = np.sum(opt_num) \n",
    "    full_product_df['Est Quantity'] = est_qnt\n",
    "    full_product_df['Actual Quantity'] = full_product_df.shape[0]\n",
    "    \n",
    "    try: \n",
    "        # Title\n",
    "        path = '//*[@class=\"product-view__name\"]'\n",
    "        title = browser.find_element_by_xpath(path).text\n",
    "        full_product_df['Title'] = title\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    print('Estimated Quantity:', est_qnt, 'Actual Quantity:', full_product_df.shape[0])\n",
    "    main_df = pd.concat([main_df, full_product_df], ignore_index=True)\n",
    "    \n",
    "    print('Main table size:', main_df.shape[0])\n",
    "    sleep(2)\n",
    "    \n",
    "    if idx%10==0:\n",
    "        with open('SCS-Wood-MainDataFrame-{}.pkl'.format(date.today().strftime(\"%d-%m-%Y\")), 'wb') as f:\n",
    "            pickle.dump(main_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('/Users/macbook/Downloads/Chrome Driver/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "waiting_time = 25\n",
    "second_main_df = pd.DataFrame()\n",
    "for idx, page_link in enumerate(option_two_links[2:], start=3):\n",
    "    print('\\nPage:', idx)\n",
    "    browser.get(page_link)\n",
    "    full_product_df = pd.DataFrame()\n",
    "    \n",
    "    dead_buttons['Link-{}'.format(idx)] = {}\n",
    "    dead_buttons['Link-{}'.format(idx)]['Option 1'] = []\n",
    "    \n",
    "    # First Option\n",
    "    sleep(3)\n",
    "    path = '//*[@id=\"product-options-wrapper\"]/dl/dd[1]/div'\n",
    "    first_input = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "\n",
    "    path = '//*[@id=\"product-options-wrapper\"]/dl/dt[1]'\n",
    "    first_option_name = browser.find_element_by_xpath(path).text\n",
    "    opt_num = []\n",
    "    for f_i, first_opt in enumerate(first_input, start=1):\n",
    "        dead_buttons['Link-{}'.format(idx)]['Option 1-{}'.format(f_i)] = []\n",
    "        \n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dd[1]/div/div/div[{}]'.format(f_i)\n",
    "        print(' \\nFirst option:', f_i)\n",
    "        try:\n",
    "            element = WebDriverWait(browser, waiting_time).until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "            element.click()\n",
    "        except:\n",
    "            dead_buttons['Link-{}'.format(idx)]['Option 1'].append(f_i)\n",
    "            print(dead_buttons)\n",
    "            continue\n",
    "\n",
    "        # Second Option\n",
    "        sleep(2)  \n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dd[2]/div'\n",
    "        second_input = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "\n",
    "        path = '//*[@id=\"product-options-wrapper\"]/dl/dt[2]'\n",
    "        second_option_name = browser.find_element_by_xpath(path).text\n",
    "        opt_num.append(len(second_input))\n",
    "        \n",
    "        for s_i, second_opt in enumerate(second_input, start=1):\n",
    "            print('Second option:', s_i)\n",
    "\n",
    "            sleep(6) \n",
    "            try:\n",
    "                path = '//*[@id=\"product-options-wrapper\"]/dl/dd[2]/div/div/div[{}]'.format(s_i)  \n",
    "                element = WebDriverWait(browser, waiting_time).until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "                element.click()\n",
    "                sleep(5)\n",
    "                \n",
    "                # Delivery\n",
    "                path = '//*[@class=\"product-view__delivery-time\"]'\n",
    "                delivery = browser.find_element_by_xpath(path).text\n",
    "\n",
    "                # Description\n",
    "                path = '//*[@class=\"product-view__collateral-main\"]'\n",
    "                description = browser.find_element_by_xpath(path).text\n",
    "\n",
    "                # Specification\n",
    "                html = browser.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                tech_data = {}\n",
    "                labels = soup.findAll(\"dt\", { \"class\" : \"technical-data__label\" })\n",
    "                values = soup.findAll(\"dd\", { \"class\" : \"technical-data__value\" })\n",
    "                for i in range(len(labels)):\n",
    "                    tech_data[labels[i].text] = values[i].text\n",
    "                tech_data = pd.DataFrame([tech_data], index=[0])\n",
    "\n",
    "            except:\n",
    "                dead_buttons['Link-{}'.format(idx)]['Option 1-{}'.format(f_i)].append(s_i)\n",
    "                print(dead_buttons)\n",
    "                continue\n",
    "\n",
    "            # Initiating page dataset\n",
    "            page_df = pd.DataFrame()\n",
    "\n",
    "            # Third Option\n",
    "            # Max Lenght\n",
    "            length_path = '//*[@id=\"product-options-wrapper\"]/div[2]/dl/dd/div/div/input'\n",
    "            browser.find_element_by_xpath(length_path).send_keys('20000')\n",
    "            browser.find_element_by_xpath(length_path).send_keys(Keys.ENTER)\n",
    "\n",
    "            path = '/html/body/div[2]/div/div[4]/div/div[2]/div[2]/form/div/div[2]/div[5]/div[2]/dl/dt/label/div'\n",
    "            max_length = browser.find_element_by_xpath(path).text.split('=')[0]\n",
    "            max_length = re.sub(' ','', max_length)\n",
    "            sleep(2)\n",
    "            browser.find_element_by_xpath(length_path).clear()\n",
    "\n",
    "            # Min Lenght\n",
    "            browser.find_element_by_xpath(length_path).send_keys('100')\n",
    "            browser.find_element_by_xpath(length_path).send_keys(Keys.ENTER)\n",
    "            path = '/html/body/div[2]/div/div[4]/div/div[2]/div[2]/form/div/div[2]/div[5]/div[2]/dl/dt/label/div'\n",
    "            min_length = browser.find_element_by_xpath(path).text.split('=')[0]\n",
    "            min_length = re.sub(' ', '', min_length)\n",
    "            sleep(2)\n",
    "            browser.find_element_by_xpath(length_path).clear()\n",
    "            \n",
    "            third_option_name = 'Länge'\n",
    "\n",
    "            for third_opt in range(int(min_length), int(max_length)+step, step):\n",
    "                browser.find_element_by_xpath(length_path).send_keys(third_opt)\n",
    "                \n",
    "                # Specific product dataset\n",
    "                product_df = pd.DataFrame([], index=[0])\n",
    "                product_df[first_option_name + '-T'] = first_opt\n",
    "                product_df[second_option_name + '-T'] = second_opt\n",
    "                product_df[third_option_name + '-T'] = third_opt\n",
    "                product_df['Delivery'] = delivery\n",
    "                product_df['Description'] = description\n",
    "                product_df['Price'] = np.nan\n",
    "\n",
    "                try:\n",
    "                    sleep(0.2)\n",
    "                    # Price\n",
    "                    path = '//*[@class=\"price-box\"]'\n",
    "                    price = browser.find_element_by_xpath(path).text\n",
    "                    product_df['Price'] = price\n",
    "\n",
    "                    product_df = pd.concat([product_df, tech_data], axis=1)\n",
    "                    page_df = pd.concat([page_df, product_df], ignore_index=True)\n",
    "                    page_df['URL'] = page_link\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                sleep(0.1)\n",
    "                browser.find_element_by_xpath(length_path).clear()\n",
    "            \n",
    "            full_product_df = pd.concat([full_product_df, page_df], ignore_index=True)\n",
    "            print('Page Product Table:', page_df.shape[0])\n",
    "        \n",
    "        print('Full Product Table:', full_product_df.shape[0])\n",
    "    try: \n",
    "        # Title\n",
    "        path = '//*[@class=\"product-view__name\"]'\n",
    "        title = browser.find_element_by_xpath(path).text\n",
    "        full_product_df['Title'] = title\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    est_qnt = np.sum(opt_num)*len(range(int(min_length), int(max_length)+step, step))\n",
    "    full_product_df['Est Quantity'] = est_qnt\n",
    "    full_product_df['Actual Quantity'] = full_product_df.shape[0]\n",
    "        \n",
    "    print('Estimated Quantity:', est_qnt, 'Actual Quantity:', full_product_df.shape[0])\n",
    "    second_main_df = pd.concat([second_main_df, full_product_df], ignore_index=True)\n",
    "    \n",
    "    print('Main table size:', second_main_df.shape[0])\n",
    "    sleep(3)\n",
    "    with open('SCS-Wood-SecondMainDataFrame-{}.pkl'.format(date.today().strftime(\"%d-%m-%Y\")), 'wb') as f:\n",
    "        pickle.dump(second_main_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([main_df, second_main_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.DataFrame({'Images':np.nan, 'URL':data['URL'].unique()}, index=range(data['URL'].nunique()))\n",
    "images_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for idx in images_df.index:\n",
    "    \n",
    "    try:\n",
    "        url = images_df['URL'].loc[idx]\n",
    "        browser.get(url)\n",
    "        sleep(1.5)\n",
    "    \n",
    "        # Click to expand the image\n",
    "        path = '//*[@class=\"product-view__main-image product-image product-image-zoom\"]'\n",
    "        browser.find_elements_by_xpath(path)[0].click()\n",
    "        sleep(1)\n",
    "\n",
    "        # Get the image\n",
    "        path = '//*[@class=\"mz-figure mz-hover-zoom mz-ready\"]/img'\n",
    "        img = browser.find_elements_by_xpath(path)[0].get_attribute('src')\n",
    "        images_df['Images'].loc[idx]= img\n",
    "        \n",
    "        print('#',idx, url ,img)\n",
    "      \n",
    "    except:\n",
    "        print('ERROR WITH IMAGE')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df['Images'] = images_df['Images'].apply(lambda x: np.nan if x=='' else x)\n",
    "data = pd.merge(data, images_df, on='URL', how='left')\n",
    "data.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
