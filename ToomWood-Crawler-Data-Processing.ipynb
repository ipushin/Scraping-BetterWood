{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pickle\n",
    "import requests\n",
    "import math\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import cfscrape\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('/Users/macbook/Downloads/Chrome Driver/chromedriver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting page links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_links = []\n",
    "for page in range(1,23): \n",
    "    url = 'https://toom.de/c/bauen-renovieren/holz?page={}'.format(page)\n",
    "    browser.get(url)\n",
    "    \n",
    "    browser.implicitly_wait(15)\n",
    "    actions = ActionChains(browser)\n",
    "    for _ in range(25):\n",
    "        actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "        sleep(0.1)\n",
    "    \n",
    "    sleep(20)       \n",
    "    elems = browser.find_elements_by_xpath(\"//a[@href]\")\n",
    "    links_per_page = []\n",
    "    for elem in elems:\n",
    "        if '/p/' in elem.get_attribute(\"href\") and elem.get_attribute(\"href\") not in page_links:\n",
    "            page_links.append(elem.get_attribute(\"href\"))\n",
    "            links_per_page.append(elem.get_attribute(\"href\"))\n",
    "    print('Page', page, 'Links', len(links_per_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://toom.de/c/garten-freizeit/gartenbau-ausstattung/gartenbaustoffe/terrassenhoelzer?filterMaterial=Holz'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elems = browser.find_elements_by_xpath(\"//a[@href]\")\n",
    "for elem in elems:\n",
    "    if '/p/' in elem.get_attribute(\"href\") and elem.get_attribute(\"href\") not in page_links:\n",
    "        page_links.append(elem.get_attribute(\"href\"))\n",
    "len(page_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Toom-Wood-Links.pkl', 'wb') as f:\n",
    "    #pickle.dump(page_links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Toom-Wood-Links.pkl', 'rb') as f:\n",
    "    #page_links = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting options. Getting links with options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cfscrape.create_scraper()\n",
    "scraper = cfscrape.create_scraper(sess=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "check = ['Variante ausw√§hlen',': ',', ',':']\n",
    "#links_options = []\n",
    "for i in range(len(page_links)):\n",
    "    link = page_links[i]\n",
    "    sleep(0.5)\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "        sleep(randint(1,5))\n",
    "    #browser.get(link)\n",
    "    scraped_html = scraper.get(link).content\n",
    "    html = etree.HTML(scraped_html)\n",
    "\n",
    "    # Checking mult options\n",
    "    raw_options = html.xpath('//*[@class=\"o-product__variants l-col l-col--medium-12\"]//text()')\n",
    "    \n",
    "    options=[]\n",
    "    for opt in raw_options:\n",
    "        if all([opt !=x for x in check]) and len(re.findall(r'\\d',opt))==0:\n",
    "            options.append(opt)\n",
    "    if options:\n",
    "        links_options.append(link)\n",
    "        print(i, options, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Toom-Wood-Options_Links.pkl', 'wb') as f:\n",
    "    #pickle.dump(links_options, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Plain Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_pages = [x for x in page_links if x not in links_options]\n",
    "len(plain_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.DataFrame([])\n",
    "except_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, url in enumerate(plain_pages[:15]):\n",
    "    if i%5==0:\n",
    "        print(i, 'Products Table:', df_products.shape)\n",
    "        \n",
    "        #with open('Toom-Wood-Products.pkl', 'wb') as f:\n",
    "            #pickle.dump(df_products, f)\n",
    "    \n",
    "    browser.get(url)\n",
    "    sleep(randint(2,4))\n",
    "    try:\n",
    "    \n",
    "        #Header\n",
    "        path = '/html/body/div[1]/div/div[2]/section[1]/div/div[2]/div[2]/div/div/h1'\n",
    "        header = browser.find_element_by_xpath(path).text\n",
    "\n",
    "        # Price\n",
    "        path = '//*[@class=\"m-price-box__value m-price-box--highlight-price\"]'\n",
    "        price = browser.find_element_by_xpath(path).text\n",
    "\n",
    "        # SKU\n",
    "        path = '//*[@class=\"a-paragraph a-paragraph--pico a-paragraph--grey-dark\"]'\n",
    "        sku = browser.find_element_by_xpath(path).text\n",
    "\n",
    "\n",
    "        # Delivery\n",
    "        # clicking on delivery\n",
    "        path = '//*[@class=\"m-buybox-tabs__title\"]'\n",
    "        browser.find_element_by_xpath(path).click()\n",
    "\n",
    "        # delivery status\n",
    "        path = '//*[@class=\"o-tabbed-buybox__price-and-text\"]'\n",
    "        delivert_price = browser.find_element_by_xpath(path).text\n",
    "\n",
    "        # Description\n",
    "\n",
    "        path = '//*[@class=\"a-list l-space-top-s l-space-bottom-s\"]'\n",
    "        first_description = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "        \n",
    "        path = '//*[@class=\"a-paragraph l-space-top-s l-space-bottom-s\"]'\n",
    "        second_description = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "        \n",
    "        description = '; '.join(first_description) + ' | '+ '; '.join(second_description)\n",
    "\n",
    "        # Main Table\n",
    "        # Checking More Option\n",
    "        scraped_html = scraper.get(url).content\n",
    "        html = etree.HTML(scraped_html)\n",
    "        more = html.xpath('//*[@class=\"a-link m-table__show-more\"]//text()')\n",
    "        if more:\n",
    "            # Click more to show more data\n",
    "            path = '//*[@class=\"a-link m-table__show-more\"]'\n",
    "            browser.find_element_by_xpath(path).click()\n",
    "            html = browser.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            table = soup.findAll(\"table\", { \"class\" : \"m-table__content l-space-top-m\" })\n",
    "        else:\n",
    "            html = browser.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            table = soup.findAll(\"table\", { \"class\" : \"m-table__content m-table--minimized l-space-top-m\" })\n",
    "\n",
    "        # Getting Main Table\n",
    "        main_table_data = {}\n",
    "        for i in range(1,20):\n",
    "            try:\n",
    "                key = table[0].find_all('tr')[i].find_all('th')[0].text\n",
    "                value = table[0].find_all('tr')[i].find_all('td')[0].text\n",
    "                main_table_data[key] = value\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        main_table = pd.DataFrame(main_table_data, index=[0])\n",
    "        main_table['Header'] = header\n",
    "        main_table['Price'] = price\n",
    "        main_table['SKU'] = sku\n",
    "        main_table['Delivery-Price'] = delivert_price\n",
    "        main_table['Description'] = description\n",
    "        main_table['URL'] = url\n",
    "\n",
    "        # Adding data to the main Table\n",
    "        df_products = pd.concat([df_products, main_table], ignore_index=True)\n",
    "    except:\n",
    "        except_links.append(url)\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Toom-Wood-Products.pkl', 'wb') as f:\n",
    "    #pickle.dump(df_products, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting pages with selecting Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get page data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_date(url):\n",
    "    #Header\n",
    "    path = '/html/body/div[1]/div/div[2]/section[1]/div/div[2]/div[2]/div/div/h1'\n",
    "    header = browser.find_element_by_xpath(path).text\n",
    "\n",
    "    # Price\n",
    "    path = '//*[@class=\"m-price-box__value m-price-box--highlight-price\"]'\n",
    "    price = browser.find_element_by_xpath(path).text\n",
    "\n",
    "    # SKU\n",
    "    path = '//*[@class=\"a-paragraph a-paragraph--pico a-paragraph--grey-dark\"]'\n",
    "    sku = browser.find_element_by_xpath(path).text\n",
    "\n",
    "\n",
    "    # Delivery\n",
    "    # clicking on delivery\n",
    "    path = '//*[@class=\"m-buybox-tabs__title\"]'\n",
    "    browser.find_element_by_xpath(path).click()\n",
    "\n",
    "    # delivery status\n",
    "    path = '//*[@class=\"o-tabbed-buybox__price-and-text\"]'\n",
    "    delivert_price = browser.find_element_by_xpath(path).text\n",
    "\n",
    "    # Description\n",
    "\n",
    "    path = '//*[@class=\"a-list l-space-top-s l-space-bottom-s\"]'\n",
    "    description = browser.find_element_by_xpath(path).text.split('\\n')\n",
    "    description = '; '.join(description)\n",
    "\n",
    "    # Main Table\n",
    "    # Checking More Option\n",
    "    scraped_html = scraper.get(url).content\n",
    "    html = etree.HTML(scraped_html)\n",
    "    more = html.xpath('//*[@class=\"a-link m-table__show-more\"]//text()')\n",
    "    if more:\n",
    "        # Click more to show more data\n",
    "        path = '//*[@class=\"a-link m-table__show-more\"]'\n",
    "        browser.find_element_by_xpath(path).click()\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        table = soup.findAll(\"table\", { \"class\" : \"m-table__content l-space-top-m\" })\n",
    "    else:\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        table = soup.findAll(\"table\", { \"class\" : \"m-table__content m-table--minimized l-space-top-m\" })\n",
    "\n",
    "    # Getting Main Table\n",
    "    main_table_data = {}\n",
    "    for i in range(1,20):\n",
    "        try:\n",
    "            key = table[0].find_all('tr')[i].find_all('th')[0].text\n",
    "            value = table[0].find_all('tr')[i].find_all('td')[0].text\n",
    "            main_table_data[key] = value\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    main_table = pd.DataFrame(main_table_data, index=[0])\n",
    "    main_table['Header'] = header\n",
    "    main_table['Price'] = price\n",
    "    main_table['SKU'] = sku\n",
    "    main_table['Delivery-Price'] = delivert_price\n",
    "    main_table['Description'] = description\n",
    "    main_table['URL'] = browser.current_url\n",
    "\n",
    "    return main_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = 0\n",
    "for i in range(start, 4):\n",
    "    url = links_options[i]\n",
    "    \n",
    "    if url in df_products['URL'].unique() and i!=start:\n",
    "        continue\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    sleep(1)\n",
    "    scraped_html = scraper.get(url).content\n",
    "    html = etree.HTML(scraped_html)\n",
    "\n",
    "    # Checking mult options\n",
    "    raw_options = html.xpath('//*[@class=\"o-product__variants l-col l-col--medium-12\"]//text()')\n",
    "    \n",
    "    options=[]\n",
    "    check = ['Variante ausw√§hlen',': ',', ',':']\n",
    "    for opt in raw_options:\n",
    "        if all([opt !=x for x in check]) and len(re.findall(r'\\d',opt))==0:\n",
    "            options.append(opt)\n",
    "    \n",
    "    # Option 1\n",
    "    if len(options)==1:\n",
    "        print(i, 'Plain Option', options)\n",
    "        \n",
    "        # Getting Options inside the page\n",
    "        browser.get(url)\n",
    "        sleep(4)\n",
    "        attr_str = browser.find_element_by_xpath('//*[@class=\"m-variants__attribute\"]').get_attribute('innerHTML')\n",
    "        num_tags = len(re.findall('a-tag m-variants__attribute-tag', attr_str))\n",
    "        \n",
    "        # Looping through the options\n",
    "        for opt in range(2,2+num_tags):\n",
    "            sleep(6)\n",
    "            path ='/html/body/div[1]/div/div/section[1]/div/div[2]/div[3]/div[1]/div/div[2]/div/div/div[{}]/label'.format(opt)\n",
    "            browser.find_element_by_xpath(path).click()\n",
    "            \n",
    "            # Scrolling page\n",
    "            actions = ActionChains(browser)\n",
    "            for _ in range(15):\n",
    "                actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                sleep(0.1)\n",
    "            sleep(0.2)\n",
    "            for _ in range(15):\n",
    "                actions.send_keys(Keys.PAGE_UP).perform()\n",
    "                sleep(0.1)\n",
    "            \n",
    "            sleep(7)\n",
    "            main_table = get_page_date(url)\n",
    "            #display(main_table)\n",
    "            \n",
    "            \n",
    "            # Adding data to the main Table\n",
    "            df_products = pd.concat([df_products, main_table], ignore_index=True)\n",
    "            print(df_products.shape)\n",
    "\n",
    "    \n",
    "    # Option 2\n",
    "    elif len(options)==2 and options[0]==options[1]:\n",
    "        print(i, 'Plain Option with dropdown', options)\n",
    "        \n",
    "        # Get page\n",
    "        browser.get(url)\n",
    "        arrow_path ='//*[@class=\"a-icon a-icon--arrow-down m-variants__selection-icon m-variants__selection-icon--closed\"]'\n",
    "\n",
    "        attr_str = browser.find_element_by_xpath('//*[@class=\"m-variants__attribute\"]').get_attribute('innerHTML')\n",
    "        num_tags = len(re.findall('a-tag m-variants__attribute-tag', attr_str))\n",
    "        \n",
    "        \n",
    "        for i in range(2,2+num_tags):\n",
    "            sleep(3)\n",
    "            browser.find_element_by_xpath(arrow_path).click()\n",
    "            sleep(2)\n",
    "\n",
    "            path = '/html/body/div[1]/div/div/section[1]/div/div[2]/div[3]/div[1]/div/div[3]/div/div/div[{}]/label'.format(i)\n",
    "            browser.find_element_by_xpath(path).click()\n",
    "            \n",
    "            # Scrolling page\n",
    "            actions = ActionChains(browser)\n",
    "            for _ in range(15):\n",
    "                actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                sleep(0.1)\n",
    "            sleep(0.2)\n",
    "            for _ in range(10):\n",
    "                actions.send_keys(Keys.PAGE_UP).perform()\n",
    "                sleep(0.1)\n",
    "                    \n",
    "            sleep(5)\n",
    "            main_table = get_page_date(url)\n",
    "            #display(main_table)\n",
    "            \n",
    "            \n",
    "            # Adding data to the main Table\n",
    "            df_products = pd.concat([df_products, main_table], ignore_index=True)\n",
    "            print(df_products.shape)\n",
    "    \n",
    "    # Option 3\n",
    "    elif len(options)==2 and options[0]!=options[1]:\n",
    "        print(i, 'Two options', options)\n",
    "        \n",
    "        # Get page\n",
    "        browser.get(url)\n",
    "        attrs_one = browser.find_element_by_xpath('/html/body/div[1]/div/div/section[1]/div/div[2]/div[3]/div[1]/div/div[2]/div/div[1]').get_attribute('innerHTML')\n",
    "        num_tags_one = len(re.findall('a-tag m-variants__attribute-tag', attrs_one))\n",
    "\n",
    "        attrs_two = browser.find_element_by_xpath('/html/body/div[1]/div/div/section[1]/div/div[2]/div[3]/div[1]/div/div[2]/div/div[2]').get_attribute('innerHTML')\n",
    "        num_tags_two = len(re.findall('a-tag m-variants__attribute-tag', attrs_two))\n",
    "        \n",
    "        # Looping through options\n",
    "        for par_one in range(2,2+num_tags_one):\n",
    "            sleep(5)\n",
    "\n",
    "            try:\n",
    "                print('i', i)\n",
    "                path_one = '/html/body/div[1]/div/div/section[1]/div/div[2]/div[3]/div[1]/div/div[2]/div/div[1]/div[{}]/label'.format(par_one)\n",
    "                browser.find_element_by_xpath(path_one).click()\n",
    "\n",
    "                actions = ActionChains(browser)\n",
    "                for _ in range(15):\n",
    "                    actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                    sleep(0.1)\n",
    "                sleep(0.2)\n",
    "                for _ in range(10):\n",
    "                    actions.send_keys(Keys.PAGE_UP).perform()\n",
    "                    sleep(0.1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "            for par_two in range(2,2+num_tags_two):\n",
    "                try:\n",
    "                    sleep(5)\n",
    "                    path_two = '/html/body/div[1]/div/div/section[1]/div/div[2]/div[3]/div[1]/div/div[2]/div/div[2]/div[{}]/label'.format(par_two)\n",
    "                    browser.find_element_by_xpath(path_two).click()\n",
    "                    actions = ActionChains(browser)\n",
    "                    for _ in range(15):\n",
    "                        actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                        sleep(0.1)\n",
    "\n",
    "                    sleep(0.2)\n",
    "                    for _ in range(10):\n",
    "                        actions.send_keys(Keys.PAGE_UP).perform()\n",
    "                        sleep(0.1)\n",
    "\n",
    "                    sleep(5)\n",
    "                    main_table = get_page_date(url)\n",
    "                    #display(main_table)\n",
    "            \n",
    "                    # Adding data to the main Table\n",
    "                    df_products = pd.concat([df_products, main_table], ignore_index=True)\n",
    "                    print(df_products.shape)\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    \n",
    "    # Option 4\n",
    "    elif len(options)==4 and options[0]==options[2] and options[1]==options[3]:\n",
    "        print(i, 'Two options with dropdown', options)\n",
    "        arrow_path ='//*[@class=\"a-icon a-icon--arrow-down m-variants__selection-icon m-variants__selection-icon--closed\"]'\n",
    "        \n",
    "        # Get page\n",
    "        browser.get(url)\n",
    "        attrs_one = browser.find_element_by_xpath('/html/body/div[1]/div/div/section[1]/div/div[2]/div[3]/div[1]/div/div[3]/div/div[1]').get_attribute('innerHTML')\n",
    "        num_tags_one = len(re.findall('a-tag m-variants__attribute-tag', attrs_one))\n",
    "\n",
    "        attrs_two = browser.find_element_by_xpath('/html/body/div[1]/div/div/section[1]/div/div[2]/div[3]/div[1]/div/div[3]/div/div[2]').get_attribute('innerHTML')\n",
    "        num_tags_two = len(re.findall('a-tag m-variants__attribute-tag', attrs_two))\n",
    "        \n",
    "        # Looping through options\n",
    "        for par_one in range(2,2+num_tags_one):\n",
    "            try:\n",
    "                browser.find_element_by_xpath(arrow_path).click()\n",
    "                sleep(5)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                path_one = '/html/body/div[1]/div/div[2]/section[1]/div/div[2]/div[3]/div[1]/div/div[3]/div/div[1]/div[{}]/label'.format(par_one)\n",
    "                browser.find_element_by_xpath(path_one).click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            actions = ActionChains(browser)\n",
    "            for _ in range(15):\n",
    "                actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                sleep(0.1)\n",
    "\n",
    "            sleep(4)\n",
    "\n",
    "            for par_two in range(2,2+num_tags_two):\n",
    "                try:\n",
    "                    browser.find_element_by_xpath(arrow_path).click()\n",
    "                    sleep(5)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    path_two = '/html/body/div[1]/div/div[2]/section[1]/div/div[2]/div[3]/div[1]/div/div[3]/div/div[2]/div[{}]/label'.format(par_two)\n",
    "                    browser.find_element_by_xpath(path_two).click()\n",
    "                    actions = ActionChains(browser)\n",
    "                    for _ in range(15):\n",
    "                        actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                        sleep(0.1)\n",
    "\n",
    "                    sleep(3)\n",
    "                    # Get the main page\n",
    "                    main_table = get_page_date(url)\n",
    "                    #display(main_table)\n",
    "                    \n",
    "                    # Adding data to the main Table\n",
    "                    df_products = pd.concat([df_products, main_table], ignore_index=True)\n",
    "                    print(df_products.shape)\n",
    "\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = df_products.copy()\n",
    "products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Toom-Wood-All-Products.pkl', 'wb') as f:\n",
    "    #pickle.dump(products, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products[~products.duplicated(keep='last')]\n",
    "products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price/Delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = products.copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the main price\n",
    "test['Price'] = test['Price'].str.replace(r'[^\\,\\d]','').str.replace(r'\\,','.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delivery and Order Online\n",
    "test['Order-Delivery-Status'] = test['Delivery-Price'].str.split('\\ninkl. 16% MwSt.\\n', expand=True)[1]\n",
    "test['Order-Delivery-Status'] = test['Order-Delivery-Status'].str.replace(r'\\n',' ')#\n",
    "\n",
    "pat = r'Dieses Produkt k√∂nnen wir dir online leider nicht anbieten|Dieser Artikel ist nicht mehr verf√ºgbar im Markt Nordhorn'\n",
    "test['Order-Delivery-Status'] = test['Order-Delivery-Status'].str.replace(pat,'Not Available Online')\n",
    "\n",
    "pat = r'Dieses Produkt ist bald wieder verf√ºgbar'\n",
    "test['Order-Delivery-Status'] = test['Order-Delivery-Status'].str.replace(pat,'Will be available again soon')\n",
    "\n",
    "pat = r'Bestellbarkeit zur Zeit nicht pr√ºfbar'\n",
    "test['Order-Delivery-Status'] = test['Order-Delivery-Status'].str.replace(pat,'Delivery Status cannot be checked at the moment')\n",
    "\n",
    "pat = r'Reservierbar im Markt Nordhorn.+|Im Markt bestellbar in Nordhorn.+'\n",
    "test['Order-Delivery-Status'] = test['Order-Delivery-Status'].str.replace(pat,'Not Available Online')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Prices\n",
    "test['Other-Price'] = test[test['Delivery-Price'].str.contains('Paket')]['Delivery-Price'].str.split('\\ninkl. 16% MwSt.\\n', expand=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delivery Yes/No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Delivery-Status'] = np.nan\n",
    "for i in test.index:\n",
    "    if 'Lieferzeit' in test['Order-Delivery-Status'].loc[i]:\n",
    "        test['Delivery-Status'].loc[i] = 'Yes'\n",
    "    else:\n",
    "        test['Delivery-Status'].loc[i] = 'No'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['SKU'] = test['SKU'].str.replace(r'\\D','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop missed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_cols = pd.DataFrame((test.isna().sum()/test.shape[0]*100), columns=['Missed'])\n",
    "cols_del = missed_cols[missed_cols['Missed']>95].index.to_list()\n",
    "len(cols_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=cols_del)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unifying to mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Breite Descr'] = np.nan\n",
    "test['L√§nge Descr'] = np.nan\n",
    "test['St√§rke Descr'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Breite Mult'] = 1\n",
    "for i in test.index:\n",
    "    if 'cm' in test['Breite'].astype(str).loc[i]:\n",
    "        test['Breite Mult'].loc[i] = 10\n",
    "    \n",
    "    if 'mm' in test['Breite'].astype(str).loc[i]:\n",
    "        test['Breite Mult'].loc[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Breite Descr'] = test['Breite'].str.replace(r'[a-zA-Z]| ','').str.replace(r'\\,','.').astype(float)\n",
    "test['Breite Descr'] = test['Breite Descr']*test['Breite Mult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L√§nge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['L√§nge Mult'] = 1\n",
    "for i in test.index:\n",
    "    if 'cm' in test['L√§nge'].astype(str).loc[i]:\n",
    "        test['L√§nge Mult'].loc[i] = 10\n",
    "    \n",
    "    if 'mm' in test['L√§nge'].astype(str).loc[i]:\n",
    "        test['L√§nge Mult'].loc[i] = 1\n",
    "        \n",
    "    if len(re.findall(r' m$', test['L√§nge'].astype(str).loc[i]))>0:\n",
    "        test['L√§nge Mult'].loc[i] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['L√§nge Descr'] = test['L√§nge'].str.replace(r'[a-zA-Z]| ','').str.replace(r'\\,','.').astype(float)\n",
    "test['L√§nge Descr'] = test['L√§nge Descr']*test['L√§nge Mult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### St√§rke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['St√§rke Mult'] = 1\n",
    "for i in test.index:\n",
    "    if 'cm' in test['St√§rke'].astype(str).loc[i]:\n",
    "        test['St√§rke Mult'].loc[i] = 10\n",
    "    \n",
    "    if 'mm' in test['St√§rke'].astype(str).loc[i]:\n",
    "        test['St√§rke Mult'].loc[i] = 1\n",
    "        \n",
    "    if len(re.findall(r' m$', test['St√§rke'].astype(str).loc[i]))>0:\n",
    "        test['St√§rke Mult'].loc[i] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['St√§rke Descr'] = test['St√§rke'].str.replace(r'[a-zA-Z]| ','').str.replace(r'\\,','.').astype(float)\n",
    "test['St√§rke Descr'] = test['St√§rke Descr']*test['St√§rke Mult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimentions Missed. Header dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_dims = test[(test['Breite Descr'].isna()) |\n",
    "                     (test['L√§nge Descr'].isna()) |\n",
    "                     (test['St√§rke Descr'].isna())].index.to_list()\n",
    "len(missed_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Header Dims'] = test['Header'].str.replace(r'^.+?(?=\\d+ x)|^.+?(?=\\d+x)','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Dims Mult'] = test['Header Dims'].str.extract(r'(cm)|(mm)', expand=True)[0]\n",
    "test['Dims Mult'] = test['Dims Mult'].fillna(test['Header Dims'].str.extract(r'(cm)|(mm)', expand=True)[1])\n",
    "\n",
    "test['Dims Mult'] = test['Dims Mult'].str.replace(r'(?<=cm).+|(?<=mm).+','')\n",
    "test['Dims Mult'] = test['Dims Mult'].str.replace(r'.+(?=mm)|.+(?=cm)','')\n",
    "test['Dims Mult'] = test['Dims Mult'].str.replace(r' $|^ ','')\n",
    "test['Dims Mult'] = test['Dims Mult'].str.replace('cm','10').str.replace('mm','1')\n",
    "\n",
    "test['Dims Mult'] = test['Dims Mult'].apply(lambda x: 1 if x!='1' and x !='10' else x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['Dims Mult'] = test['Dims Mult'].apply(lambda x: np.nan if x!='1' and x!='10' else x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Breite Header'] = np.nan\n",
    "test['L√§nge Header'] = np.nan\n",
    "test['St√§rke Header'] = np.nan\n",
    "\n",
    "for i in missed_dims:\n",
    "    width = np.nan\n",
    "    thick = np.nan\n",
    "    length = np.nan\n",
    "    \n",
    "    try:\n",
    "        length = test['Header Dims'].loc[i].split('x')[0]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        width = test['Header Dims'].loc[i].split('x')[1]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        thick = test['Header Dims'].loc[i].split('x')[2]\n",
    "    except:\n",
    "        pass     \n",
    "    \n",
    "    test['Breite Header'].loc[i] = width\n",
    "    test['L√§nge Header'].loc[i] = length\n",
    "    test['St√§rke Header'].loc[i] = thick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Breite Header','L√§nge Header','St√§rke Header']:\n",
    "    \n",
    "    test[col] = test[col].fillna('').astype(str).str.replace(r'[a-zA-Z]| ','').str.replace(r'\\,','.').str.replace(r' ','')#\n",
    "    test[col] = test[col].fillna('').astype(str).str.replace(r'[^\\.\\d]|\\.$','').str.replace(r'^\\.','')\n",
    "    test[col] = test[col].apply(lambda x: np.nan if x==' ' or x=='' else x )\n",
    "    \n",
    "    test[col] = test[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in missed_dims:\n",
    "    for col in ['Breite Header','L√§nge Header','St√§rke Header']:\n",
    "        test[col].loc[i] = test[col].loc[i]*test['Dims Mult'].loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_dims = test[(test['Breite Descr'].isna()) &\n",
    "                   (test['L√§nge Descr'].isna()) &\n",
    "                   (test['St√§rke Descr'].isna()) &\n",
    "                   (test['Breite Header'].isna()) &\n",
    "                   (test['L√§nge Header'].isna()) &\n",
    "                   (test['St√§rke Header'].isna())].index.to_list()\n",
    "len(missed_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Breite Header'] = test['Breite Header'].fillna(test['Breite Descr'])\n",
    "test['L√§nge Header'] = test['L√§nge Header'].fillna(test['L√§nge Descr']) \n",
    "test['St√§rke Header'] = test['St√§rke Header'] .fillna(test['St√§rke Descr']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_cols = ['Header','Header Dims','Breite New','L√§nge New','St√§rke New','Dims Mult',\n",
    "             'Breite Header','L√§nge Header','St√§rke Header']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['Header','Header Dims','Breite Descr','L√§nge Descr','St√§rke Descr','Dims Mult',\n",
    "     'Breite Header','L√§nge Header','St√§rke Header']].loc[missed_dims].sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Header Meta'] = test['Header'].str.replace(r'[^a-zA-Z]', ' ').str.replace(r'  +', ' ').str.replace(r' x .+', '')\n",
    "test['Header Meta'] = test['Header Meta'].str.replace(r' wei|toom ', '').str.replace(r' [A-Z]$|^[A-Z] | [a-z]$|^ [a-z]', '')\n",
    "test['Header Meta'] = test['Header Meta'].str.replace(r' [a-z] | [A-Z] ', ' ').str.replace(r'^ |easy| St ck|WandArt| mm| cm', '')#.value_counts() #.value_counts()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_del =['Marke','R√§ume','Serie','H√∂he', 'Einsatzbereich', 'Lieferumfang','Ausf√ºhrung',\n",
    "         'Inhalt','Geeignet f√ºr','Kanten','Kantenausf√ºhrung','Maserung','Modell','Zuschnitts-Option']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wood Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woods = ['Ahorn', 'Tanne', 'Sperrholz', 'Nussbaum', 'Erle',\n",
    "        'Bongossi (Azob√©)', 'Birke', 'Buche', 'Douglasie',\n",
    "        'Edelkastanie', 'Eiche', 'Elsbeere', 'Erle', 'Esche', 'Fichte',\n",
    "        'Kiefer', 'Kirschbaum', 'L√§rche', 'Linde', 'Mahagoni', 'Teak',\n",
    "        'Pappel', 'Robinie', 'Tanne', 'Ulme', 'Walnuss', 'Weide', 'Birne',\n",
    "        'Fichte/Tanne', 'Fichte/Kiefer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Header Wood'] = ''\n",
    "for i in test.index:\n",
    "    for wood in woods:\n",
    "        pat = r' {} |^{} | {}$'.format(wood.lower(), wood.lower(), wood.lower())\n",
    "        if len(re.findall(pat, test['Header Meta'].loc[i].lower()))>0:\n",
    "        #if len(wood.lower() in test['Header Meta'].loc[i].lower():\n",
    "            test['Header Wood'].loc[i] = wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Description Wood'] = ''\n",
    "for i in test.index:\n",
    "    for wood in woods:\n",
    "        pat = r' {} |^{} | {}$'.format(wood.lower(), wood.lower(), wood.lower())\n",
    "        if len(re.findall(pat, test['Description'].loc[i].lower()))>0:\n",
    "            test['Description Wood'].loc[i] = wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Header Wood','Description Wood']:\n",
    "    test[col] = test[col].apply(lambda x: np.nan if x==' ' or x=='' else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['Header','Header Wood',\n",
    "      'Description','Description Wood']].isna().sum()/test.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['Header','Header Wood',\n",
    "      'Description','Description Wood']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Wood Type'] = test['Materialspezifizierung'].fillna(test['Material']).fillna(test['Header Wood']).fillna(test['Description Wood'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheking wrong typs and woods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_wood = ['Holzwerkstoff (MDF)', 'Glas', 'Stahl', 'Aluminium', 'Metall', 'Granit', 'Polymere', 'Granito',\n",
    "             'Kunststoff','Laminiert','Gipskarton, Furniert','PVC','Beschichtet', 'Spanholz', 'Melaminbeschichtet' ,\n",
    "              'Furniert','PVC-freie Werkstoffmischung',  'Foliert',  'Laminiert', 'Holz, Polymere','Polycarbonat',\n",
    "              'Polyvinylchlorid (PVC)','Gipskarton','German Compact Composite (GCC)','Bandstahl','Foliert',\n",
    "              'Faseprofil','Metall, Kunststoff', 'Textil, Kunststoff','Rotbuche','Kirschbaum','Multiplex',\n",
    "              'Qualit√§tsspanplatte mit HPL-Beschichtung Profil aus Hart-PVC','Holz-Kunststoff-Verbundwerkstoffe (WPC)'\n",
    "              ,'Beschichtete Flachpressplatte', 'Hart-PVC-Leiste','Holz, Kunststoff','Lackiert','WPC','Kunststoff', \n",
    "              'Stahl','Weich-PVC','Kunststoff, Metall','Unbehandelt','Kunststoffbeschichtet','Kunststoffummantelter Hartfaserkern',\n",
    "             'Kunststoff, Stahl','Beschichtete Flachpressplatte, Hart-PVC-Leiste','Beidseitig mit HPL beschichtete Spanplatte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[(~test['Wood Type'].isin(wrong_wood))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[(~test['Wood Type'].isin(wrong_wood))]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Wood Type'] = test['Wood Type'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all columns to mine text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_cols = ['Materialspezifizierung',  'Paketinhalt', \n",
    "           'Header', 'Description', \n",
    "           'Herstellerfarbe', 'Artikeltyp', 'Oberfl√§che', 'Marke', 'Farbe',\n",
    "           'Hinweistext', 'Tiefe', 'Ausf√ºhrung', 'Tragkraft pro Boden',\n",
    "           'Verdeckte Montageleiste', 'Gewicht', 'Inhalt', 'Einsatzbereich',\n",
    "           'Material', 'Serie', 'Montageart', 'Lieferumfang', 'H√∂he', 'Tragkraft',\n",
    "           'Durchmesser Rad', 'Design', 'Holzart',\n",
    "           'Herkunftsland', 'Kantenverarbeitung', 'Geeignet f√ºr',\n",
    "           'Nutwangenst√§rke', 'Lichtdurchl√§ssig', 'Set', 'Maserung', 'Modell',\n",
    "           'Kantenausf√ºhrung', 'Zuschnitts-Option', 'Durchmesser', 'Form',\n",
    "           'Sortierung', 'R√§ume', 'Kanten', 'Norm', 'Zuschnittartikel',\n",
    "           'Passend f√ºr', 'L√§nge min.', 'Kabelf√ºhrung', 'Endlos verlegbar',\n",
    "           'Packungsinhalt reicht f√ºr', 'Fugenart', 'Deckfl√§che', 'Profil',\n",
    "           'Geeignet f√ºr Anstriche', 'Haltbarkeit im Au√üenbereich', 'Harzhaltig',\n",
    "           'Verzug', 'Schwind- & Quellverhalten', 'Rissig', 'Bearbeitbarkeit',\n",
    "           'Art der Verlegung', 'Eigenschaften', 'Nutma√ü',\n",
    "           'Geeignet f√ºr Feuchtraum', 'T√ºrvariante', 'Order-Delivery-Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined'] = ''\n",
    "for col in comb_cols:\n",
    "    test['Combined'] = test['Combined'] + '; ' + test[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined'] = test['Combined'].str.replace(r'\\; nan','').str.replace(r'^; ','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_surfaces = ['geschliffen', 'gehobelt', 'gefast',\n",
    "                   's√§gerau', 'geriffelt', 'glatt gehobelt', 'glatte', 'gefr√§st',\n",
    "                   'geb√ºrstet', 'strukturiert', '1-Seitig gehobelt',\n",
    "                   '2-Seitig gehobelt', '3-Seitig gehobelt', '4-Seitig gehobelt',\n",
    "                   'genutet', 'unbehandelt', 'naturbelassen', \n",
    "                   'deckend', 'lasiert', 'vorge√∂lt', 'kesseldruckimpr√§gniert (KDI)',\n",
    "                   'hitzebehandelt', 'thermobehandelt', 'wachsen', 'impr√§gniert',\n",
    "                   'Scharfkantig']\n",
    "\n",
    "weak_surfaces = ['roh', 'keine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Header Surface Treat'] = ''\n",
    "for i in test.index:\n",
    "    test['Header Surface Treat'].loc[i] = []\n",
    "    for surface in weak_surfaces:\n",
    "        pat = r' {} |^{} | {}$'.format(surface.lower(), surface.lower(), surface.lower())\n",
    "        if len(re.findall(pat, test['Header Meta'].loc[i].lower()))>0:\n",
    "            test['Header Surface Treat'].loc[i].append(surface)\n",
    "    \n",
    "    for surface in strong_surfaces:\n",
    "        if surface.lower() in test['Header Meta'].loc[i].lower():\n",
    "            test['Header Surface Treat'].loc[i].append(surface)\n",
    "    try:\n",
    "        test['Header Surface Treat'].loc[i] = ', '.join(test['Header Surface Treat'].loc[i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Description Surface Treat'] = ''\n",
    "for i in test.index:\n",
    "    test['Description Surface Treat'].loc[i] = []\n",
    "    for surface in weak_surfaces:\n",
    "        pat = r' {} |^{} | {}$'.format(surface.lower(), surface.lower(), surface.lower())\n",
    "        if len(re.findall(pat, test['Description'].loc[i].lower()))>0:\n",
    "            test['Description Surface Treat'].loc[i].append(surface)\n",
    "    \n",
    "    for surface in strong_surfaces:\n",
    "        if surface.lower() in test['Description'].loc[i].lower():\n",
    "            test['Description Surface Treat'].loc[i].append(surface)\n",
    "    try:\n",
    "        test['Description Surface Treat'].loc[i] = ', '.join(test['Description Surface Treat'].loc[i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined Surface Treat'] = ''\n",
    "for i in test.index:\n",
    "    test['Combined Surface Treat'].loc[i] = []\n",
    "    for surface in weak_surfaces:\n",
    "        pat = r' {} |^{} | {}$'.format(surface.lower(), surface.lower(), surface.lower())\n",
    "        if len(re.findall(pat, test['Combined'].loc[i].lower()))>0 and surface.lower() not in ', '.join(test['Combined Surface Treat'].loc[i]):\n",
    "            test['Combined Surface Treat'].loc[i].append(surface)\n",
    "    \n",
    "    for surface in strong_surfaces:\n",
    "        if surface.lower() in test['Combined'].loc[i].lower() and surface.lower() not in ', '.join(test['Combined Surface Treat'].loc[i]):\n",
    "            test['Combined Surface Treat'].loc[i].append(surface)\n",
    "    try:\n",
    "        test['Combined Surface Treat'].loc[i] = ', '.join(test['Combined Surface Treat'].loc[i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Combined Surface Treat', 'Header Surface Treat','Description Surface Treat']:\n",
    "    test[col] = test[col].apply(lambda x: np.nan if x==' ' or x=='' else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['Header','Header Surface Treat',\n",
    "      'Description','Description Surface Treat',\n",
    "      'Add Description','Combined Surface Treat']].isna().sum()/test.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Header','Header Surface Treat',\n",
    "        'Description','Description Surface Treat',\n",
    "        'Oberfl√§che','Combined Surface Treat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[((~test['Header Surface Treat'].isna()) |\n",
    "     (~test['Description Surface Treat'].isna())) & \n",
    "     (test['Combined Surface Treat'].isna()) ][cols].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['Combined Surface Treat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[((~test['Header Surface Treat'].isna()) |\n",
    "     (~test['Description Surface Treat'].isna())) &\n",
    "     (test['Oberfl√§che'].isna()) ][cols].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drying method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_method = ['technischer trocknung','technisch getrocknet', 'kammer getrocknet',\n",
    "               'kammertrocken', 'AD (luftgetrocknet)',\n",
    "               'KD (K√ºnstlich getrocknet)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined Drying Method'] = ''\n",
    "for i in test.index:\n",
    "    test['Combined Drying Method'].loc[i] = []\n",
    "    for method in dry_method:\n",
    "        if method.lower() in test['Combined'].loc[i].lower() and method.lower() not in ', '.join(test['Combined Drying Method'].loc[i]):\n",
    "            test['Combined Drying Method'].loc[i].append(method)\n",
    "        \n",
    "    try:\n",
    "        test['Combined Drying Method'].loc[i] = ', '.join(test['Combined Drying Method'].loc[i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined Drying Method'] =  test['Combined Drying Method'].apply(lambda x: np.nan if x==' ' or x=='' else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined Drying Method'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_quality = ['NSI', 'SI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined Surface Quality'] = ''\n",
    "for i in test.index:\n",
    "    test['Combined Surface Quality'].loc[i] = []\n",
    "    for surf_qual in surf_quality:\n",
    "        pat = r' {} |^{} | {}$|[a-z] {}\\;'.format(surf_qual.lower(), surf_qual.lower(), surf_qual.lower(), surf_qual.lower())\n",
    "        if len(re.findall(pat, test['Combined'].loc[i].lower()))>0 and surf_qual.lower() not in ', '.join(test['Combined Surface Quality'].loc[i]):\n",
    "            test['Combined Surface Quality'].loc[i].append(surf_qual)\n",
    "            \n",
    "    try:\n",
    "        test['Combined Surface Quality'].loc[i] = ', '.join(test['Combined Surface Quality'].loc[i])\n",
    "    except:\n",
    "        pass\n",
    "test['Combined Surface Quality'] =  test['Combined Surface Quality'].apply(lambda x: np.nan if x==' ' or x=='' else x )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined Surface Quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = ['A-Sortierung', 'B-Sortierung', 'C-Sortierung', 'A/B', 'B/C','Kl. A', '1.Wahl Sortierung', 'Altholz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined Quality'] = ''\n",
    "for i in test.index:\n",
    "    test['Combined Quality'].loc[i] = []\n",
    "    for qual in quality:\n",
    "        pat = r' {} |^{} | {}$| {}\\;'.format(qual.lower(), qual.lower(), qual.lower(), qual.lower())\n",
    "        if len(re.findall(pat, test['Combined'].loc[i].lower()))>0 and qual.lower() not in ', '.join(test['Combined Quality'].loc[i]):\n",
    "            test['Combined Quality'].loc[i].append(qual)\n",
    "            \n",
    "    try:\n",
    "        test['Combined Quality'].loc[i] = ', '.join(test['Combined Quality'].loc[i])\n",
    "    except:\n",
    "        pass\n",
    "test['Combined Quality'] =  test['Combined Quality'].apply(lambda x: np.nan if x==' ' or x=='' else x )\n",
    "test['Combined Quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_classes = ['S7', 'S10', 'S13', 'C16M', 'C24M', 'C30M', 'D30', 'D35', 'D40',\n",
    "               'D60', 'D70', 'geringe Tragf√§higkeit', 'mittlere Tragf√§higkeit',\n",
    "               'hohe Tragf√§higkeit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Combined Sorting Class'] = ''\n",
    "for i in test.index:\n",
    "    test['Combined Sorting Class'].loc[i] = []\n",
    "    for sort_class in sort_classes:\n",
    "        pat = r' {} |^{} | {}$| {}\\;'.format(sort_class.lower(), sort_class.lower(), sort_class.lower(), sort_class.lower())\n",
    "        if len(re.findall(pat, test['Combined'].loc[i].lower()))>0 and sort_class.lower() not in ', '.join(test['Combined Sorting Class'].loc[i]):\n",
    "            test['Combined Sorting Class'].loc[i].append(sort_class)\n",
    "       \n",
    "    try:\n",
    "        test['Combined Sorting Class'].loc[i] = ', '.join(test['Combined Sorting Class'].loc[i])\n",
    "    except:\n",
    "        pass\n",
    "test['Combined Sorting Class'] =  test['Combined Sorting Class'].apply(lambda x: np.nan if x==' ' or x=='' else x )\n",
    "test['Combined Sorting Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Surfase Treatment'] = test['Oberfl√§che'].fillna(test['Description Surface Treat']).fillna(test['Header Surface Treat'])\n",
    "test['Surfase Treatment'] = test['Surfase Treatment'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinig columns for parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Product Type'] = test['Artikeltyp'].fillna(test['Header Meta'])\n",
    "test['Color'] = test['Herstellerfarbe'].fillna(test['Farbe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test.index:\n",
    "    for wood in woods:\n",
    "        if wood.lower() in test['Product Type'].loc[i].lower():\n",
    "            test['Product Type'].loc[i] = re.sub(wood,'', test['Product Type'].loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Product Type'] = test['Product Type'].str.replace(r' +', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test.columns:\n",
    "    test[col] =  test[col].apply(lambda x: np.nan if x =='' or x == 'nan' or x == ' ' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Product Type New'] = test['Product Type'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test.index:\n",
    "    \n",
    "    if 'regalbo' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'regalboden'\n",
    "        \n",
    "    if 'holzrundst' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'holzrundstab'\n",
    "        \n",
    "    if 'bauplatte' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'bauplatte'\n",
    "        \n",
    "    if 'leiste' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'leiste'  \n",
    "    \n",
    "    if 'profil' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'profil' \n",
    "    \n",
    "    if 'woodstone' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'woodstone'\n",
    "    \n",
    "    if 'rahmen' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'rahmenholz'\n",
    "    \n",
    "    if 'allwetter' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'allwetterholz'\n",
    "    \n",
    "    if 'leimholz' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'leimholz'\n",
    "    \n",
    "    if 'konstruktion' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'konstruktionsholz'\n",
    "    \n",
    "    if 'arbeitsplatte' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'arbeitsplatte'\n",
    "    \n",
    "    if 'lamellent' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'lamellent'\n",
    "    \n",
    "    if 'terrassendiel' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'terrassendiele'\n",
    "    \n",
    "    if 'stab' in  test['Product Type New'].astype(str).loc[i].lower():\n",
    "        test['Product Type New'].loc[i] = 'stab'\n",
    "    \n",
    "  \n",
    "test['Product Type New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_types = test['Product Type New'].value_counts()[:35].index.to_list()\n",
    "#test = test[test['Product Type New'].isin(right_types)]\n",
    "test[test['Product Type New'].isin(right_types)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['Product Type New'].isin(right_types)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[(test['Product Type New']!='praktikus kantenumleimer ') & \n",
    "            (test['Product Type New']!='verlegeplatte span geschliffen') & \n",
    "            (test['Product Type New']!='belfront room ') & \n",
    "            (test['Product Type New']!='verlegeplatte span geschliffen') & \n",
    "            (test['Product Type New']!='viertelstab nadelholz') &\n",
    "            (test['Product Type New']!='steckpaneele vario edelwei') & \n",
    "            (test['Product Type New']!='regalelement segment')& \n",
    "            (test['Product Type New']!='endst√ºck')&\n",
    "            (test['Product Type New']!='holzkugel')\n",
    "           ]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Product Type New'] = test['Product Type New'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df2gspread import gspread2df as g2d\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "spreadsheet_key = '1iDGux_PxTPSIkxnljeEhMifJo5jAXDhxOXLB8zlrOKg'\n",
    "scope = ['https://spreadsheets.google.com/feeds'] \n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('/Users/macbook/Downloads/gs-credentials.json', scope) \n",
    "keywords = g2d.download(gfile=spreadsheet_key, wks_name = 'Keywords', credentials=credentials, col_names=True, row_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols = {'Produktart':'Product Type', \n",
    "               'Holztyp':'Wood Type',\n",
    "               'Qualit√§t':'Quality',\n",
    "               'Oberfl√§chenqualit√§t':'Surface Quality',\n",
    "               'Sortierklasse':'Sorting Class',\n",
    "               'Trocknung':'Drying Method'}\n",
    "keywords = keywords.rename(columns=rename_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in keywords.columns:\n",
    "    keywords[col] = keywords[col].apply(lambda x: np.nan if x == '' or x == ' ' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keywords['Wood Type'].loc[31] = 'Holz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df = matched_df.drop(columns='Product Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ren_cols = {'Product Type New':'Product Type',\n",
    "           'Combined Sorting Class':'Sorting Class',\n",
    "           'Combined Quality':'Quality',\n",
    "            'Combined Drying Method':'Drying Method',\n",
    "            'Combined Surface Treat':'Surface Treatment',\n",
    "           'Combined Surface Quality':'Surface Quality'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df = matched_df.rename(columns=ren_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cols = ['URL','SKU','Header','Product Type','Wood Type','Surface Treatment','Surface Quality',\n",
    "             'Drying Method','Sorting Class','Quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df[main_cols].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df['Matched Keywords'] = np.nan\n",
    "matched_df['Other Keywords'] = np.nan\n",
    "matched_df = matched_df.fillna('-777')\n",
    "keywords = keywords.fillna('-999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_keywords(row):\n",
    "    row['Matched Keywords'] = {}\n",
    "    row['Other Keywords'] = {}\n",
    "    \n",
    "    matched_cols=[]\n",
    "    for col in ['Product Type','Wood Type','Surface Treatment','Surface Quality',\n",
    "                'Drying Method','Sorting Class','Quality']:\n",
    "        \n",
    "        for key_word in keywords[col].unique():\n",
    "            if fuzz.token_set_ratio(str(row[col]).lower(), key_word.lower()) > 90 or key_word.lower() in str(row[col]):\n",
    "                row['Matched Keywords'][row[col]] = key_word\n",
    "                matched_cols.append(col)\n",
    "    \n",
    "    if len(matched_cols)==0:\n",
    "        row['Other Keywords'] = np.nan\n",
    "        row['Matched Keywords'] = np.nan\n",
    "    \n",
    "    for col in ['Product Type','Wood Type','Surface Treatment','Surface Quality',\n",
    "                'Drying Method','Sorting Class','Quality']:\n",
    "        \n",
    "        if col not in matched_cols and len(matched_cols)>0 and row[col]!=-999:\n",
    "            row['Other Keywords'][col] = row[col]\n",
    "    \n",
    "    return row\n",
    "matched_df = matched_df.apply(get_keywords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df[['Matched Keywords','Other Keywords']].isna().sum()/matched_df.shape[0]*100, matched_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Product Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df[(~matched_df['Matched Keywords'].isna()) &\n",
    "           (~matched_df['Wood Type'].isin(wrong_wood_second))\n",
    "          ]['Product Type'].shape#.nunique()#value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning product types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in matched_df.index:\n",
    "    \n",
    "    for word in ['kantenumleimer','bodendiele','umleimer','holzfliese','rauspund','hobeldiele',\n",
    "                'vielzweckplatte','grobspanplatte','brettschichtholz','universalbrett',\n",
    "                'unterkonstonstruktion','wandabschluss zubeh','dekorkante getalit','massivholzplatte',\n",
    "                'verbindungsecken','verlegeplatte']:\n",
    "        \n",
    "        if word in matched_df['Product Type'].astype(str).loc[i].lower():\n",
    "            matched_df['Product Type'].loc[i] = word\n",
    "  \n",
    "matched_df[(~matched_df['Matched Keywords'].isna()) &\n",
    "           (~matched_df['Wood Type'].isin(wrong_wood_second))\n",
    "          ]['Product Type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace('uk latten','uk latte')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace('latte impr gniert','latte')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace('ausgleichsh lzer rotbuche','ausgleichsh√∂lzer')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace('ckwandsystemset fantasie|ckwand system set getalit edelstahl optik tlg ','r√ºckwandsystemset')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace('konuspl ttchen ','konuspl√§ttchen ')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace('klenk holz','')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace('st lpschalungsbretter ','st√ºlpschalungsbretter')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace(r'^ | $','')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace(r'diele grau impr gniert geriffelt glatt','diele')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace(r'wpc klickfliesen er set anthrazit','klickfliesen')\n",
    "matched_df['Product Type'] = matched_df['Product Type'].str.replace(r'st lpschalung','st√ºlpschalung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df['Product Type'] = matched_df['Product Type'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df[(~matched_df['Matched Keywords'].isna()) &\n",
    "           (~matched_df['Wood Type'].isin(wrong_wood_second))\n",
    "          ]['Product Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_wood_second = ['Polycarbonat', 'Kunststoff', 'PVC', 'German Compact Composite (GCC)', \n",
    "                     'Foliert', 'WPC', 'Metall', 'Multiplex', 'Beschichtet', 'Stahl']\n",
    "#wrong_wood_second = [x for x in matched_df[(~matched_df['Matched Keywords'].isna())]['Wood Type'].unique() if  x in wrong_wood]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df[(~matched_df['Matched Keywords'].isna()) &\n",
    "           (~matched_df['Wood Type'].isin(wrong_wood_second))\n",
    "          ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df[(matched_df['Matched Keywords'].isna()) & \n",
    "          (matched_df['Wood Type']=='Holz')][main_cols].shape#['Wood Type'].value_counts()#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df[(matched_df['SKU'].str.contains('7200058')) &\n",
    "            (~matched_df['Matched Keywords'].isna()) &\n",
    "            (~matched_df['Wood Type'].isin(wrong_wood))]['Product Type'].shape#value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df[(~matched_df['Matched Keywords'].isna()) #&\n",
    "           #(~matched_df['Wood Type'].isin(wrong_wood))\n",
    "          ]['Product Type'].nunique()#value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in matched_df.columns:\n",
    "    matched_df[col] = matched_df[col].apply(lambda x: np.nan if x == '' or x == ' ' or x=='-999' or x=='-777' or x=='nan'else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from df2gspread import df2gspread as d2g\n",
    "scope = ['https://spreadsheets.google.com/feeds'] \n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('/Users/macbook/Downloads/gs-credentials.json', scope) \n",
    "gc = gspread.authorize(credentials)\n",
    "spreadsheet_key = '1iDGux_PxTPSIkxnljeEhMifJo5jAXDhxOXLB8zlrOKg'\n",
    "#sheets-juputer@jupyter-sheets-270906.iam.gserviceaccount.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Website Name', 'URL','Header','Product Type','Wood Type', 'Breite Header', 'L√§nge Header', 'St√§rke Header', \n",
    "        'Price','Delivery-Status','Quality', 'Surface Quality','Surface Treatment','Drying Method',\n",
    "        'Sorting Class','SKU','Order-Delivery-Status' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_clean = matched_df[(~matched_df['Matched Keywords'].isna()) &\n",
    "                          (~matched_df['Wood Type'].isin(wrong_wood_second)) ]\n",
    "sheets_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_clean = sheets_clean[(~sheets_clean.duplicated(subset='URL', keep='last'))]\n",
    "sheets_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_clean['Website Name'] = 'www.toom.de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_dims = sheets_clean[(sheets_clean['Breite Header'].isna()) &\n",
    "                           (sheets_clean['L√§nge Header'].isna()) &\n",
    "                           (sheets_clean['St√§rke Header'].isna())].index.to_list()\n",
    "len(missed_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sheets_clean[cols].loc[missed_dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ren_cols = {'Header':'Product Title',\n",
    "           'Breite Header':'Width (mm)',\n",
    "           'L√§nge Header':'Length (mm)', \n",
    "           'St√§rke Header':'Thickness (mm)',\n",
    "            'Price':'Price (Euro)',\n",
    "            'Order-Delivery-Status':'Delivery Status',\n",
    "            'Delivery-Status':'Order Delivery (Y/N)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_clean = sheets_clean[cols].rename(columns = ren_cols).fillna('-')\n",
    "sheets_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2g.upload(sheets_clean,\n",
    "           spreadsheet_key,\n",
    "           'Toom Clean Data',\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = 'A1',\n",
    "           clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data Toom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_raw = matched_df[(~matched_df.duplicated(subset='URL', keep='last'))]\n",
    "sheets_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_raw['Website Name'] = 'www.toom.de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_raw = sheets_raw[cols].rename(columns = ren_cols).fillna('-')\n",
    "sheets_raw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2g.upload(sheets_raw,\n",
    "           spreadsheet_key,\n",
    "           'Toom Raw Data',\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = 'A1',\n",
    "           clean=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
